#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»æ§åˆ¶è„šæœ¬
å¯ä»¥å•ç‹¬è¿è¡Œå„ä¸ªæµç¨‹æˆ–å®Œæ•´æµç¨‹
"""

import os
import sys
import logging
from datetime import datetime

# å¯¼å…¥å„ä¸ªæµç¨‹
from data_collection_pipeline import DataCollectionPipeline
from report_generation_pipeline import ReportGenerationPipeline
from document_conversion_pipeline import DocumentConversionPipeline

def setup_logging():
    """é…ç½®ä¸»æ§åˆ¶è„šæœ¬çš„æ—¥å¿—"""
    os.makedirs("logs", exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_filename = f"logs/main_pipeline_{timestamp}.log"
    
    logger = logging.getLogger('MainPipeline')
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    console_handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

def run_data_collection(company="å•†æ±¤ç§‘æŠ€", code="00020", market="HK", search_engine="all"):
    """è¿è¡Œæ•°æ®æ”¶é›†æµç¨‹"""
    logger = logging.getLogger('MainPipeline')
    logger.info("\n" + "="*100)
    logger.info("ğŸ¯ å¼€å§‹æ•°æ®æ”¶é›†æµç¨‹")
    logger.info("="*100)
    
    try:
        pipeline = DataCollectionPipeline(
            target_company=company,
            target_company_code=code,
            target_company_market=market,
            search_engine=search_engine
        )
        
        success = pipeline.run_data_collection()
        
        if success:
            logger.info("âœ… æ•°æ®æ”¶é›†æµç¨‹å®Œæˆ")
            return True
        else:
            logger.error("âŒ æ•°æ®æ”¶é›†æµç¨‹å¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ”¶é›†æµç¨‹å¼‚å¸¸: {e}")
        return False

def run_report_generation(company="å•†æ±¤ç§‘æŠ€", code="00020", market="HK"):
    """è¿è¡Œç ”æŠ¥ç”Ÿæˆæµç¨‹"""
    logger = logging.getLogger('MainPipeline')
    logger.info("\n" + "="*100)
    logger.info("ğŸ¯ å¼€å§‹ç ”æŠ¥ç”Ÿæˆæµç¨‹")
    logger.info("="*100)
    
    try:
        pipeline = ReportGenerationPipeline(
            target_company=company,
            target_company_code=code,
            target_company_market=market
        )
        
        output_file = pipeline.generate_report()
        
        if output_file:
            logger.info(f"âœ… ç ”æŠ¥ç”Ÿæˆæµç¨‹å®Œæˆ: {output_file}")
            return output_file
        else:
            logger.error("âŒ ç ”æŠ¥ç”Ÿæˆæµç¨‹å¤±è´¥")
            return None
            
    except Exception as e:
        logger.error(f"âŒ ç ”æŠ¥ç”Ÿæˆæµç¨‹å¼‚å¸¸: {e}")
        return None

def run_document_conversion(md_path=None):
    """è¿è¡Œæ–‡æ¡£è½¬æ¢æµç¨‹"""
    logger = logging.getLogger('MainPipeline')
    logger.info("\n" + "="*100)
    logger.info("ğŸ¯ å¼€å§‹æ–‡æ¡£è½¬æ¢æµç¨‹")
    logger.info("="*100)
    
    try:
        pipeline = DocumentConversionPipeline()
        
        result = pipeline.run_conversion(md_path)
        
        if result:
            logger.info("âœ… æ–‡æ¡£è½¬æ¢æµç¨‹å®Œæˆ")
            return result
        else:
            logger.error("âŒ æ–‡æ¡£è½¬æ¢æµç¨‹å¤±è´¥")
            return None
            
    except Exception as e:
        logger.error(f"âŒ æ–‡æ¡£è½¬æ¢æµç¨‹å¼‚å¸¸: {e}")
        return None

def run_full_pipeline(company="å•†æ±¤ç§‘æŠ€", code="00020", market="HK", search_engine="all"):
    """è¿è¡Œå®Œæ•´æµç¨‹"""
    logger = logging.getLogger('MainPipeline')
    logger.info("\n" + "="*100)
    logger.info("ğŸ¯ å¼€å§‹å®Œæ•´ç ”æŠ¥ç”Ÿæˆæµç¨‹")
    logger.info("="*100)
    
    try:
        # 1. æ•°æ®æ”¶é›†
        logger.info("ğŸ“Š ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æ”¶é›†")
        if not run_data_collection(company, code, market, search_engine):
            logger.error("âŒ æ•°æ®æ”¶é›†å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
            return False
        
        # 2. ç ”æŠ¥ç”Ÿæˆ
        logger.info("ğŸ“‹ ç¬¬äºŒé˜¶æ®µï¼šç ”æŠ¥ç”Ÿæˆ")
        md_file = run_report_generation(company, code, market)
        if not md_file:
            logger.error("âŒ ç ”æŠ¥ç”Ÿæˆå¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
            return False
        
        # 3. æ–‡æ¡£è½¬æ¢
        logger.info("ğŸ“„ ç¬¬ä¸‰é˜¶æ®µï¼šæ–‡æ¡£è½¬æ¢")
        conversion_result = run_document_conversion(md_file)
        if not conversion_result:
            logger.error("âŒ æ–‡æ¡£è½¬æ¢å¤±è´¥")
            return False
        
        # 4. è¾“å‡ºç»“æœ
        logger.info("\n" + "="*100)
        logger.info("ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        logger.info(f"ğŸ“Š æ•°æ®æ”¶é›†: å®Œæˆ")
        logger.info(f"ğŸ“‹ ç ”æŠ¥ç”Ÿæˆ: {md_file}")
        logger.info(f"ğŸ“„ æ–‡æ¡£è½¬æ¢: {conversion_result['docx']}")
        logger.info("="*100)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´æµç¨‹å¼‚å¸¸: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='é‡‘èç ”æŠ¥ç”Ÿæˆä¸»æ§åˆ¶è„šæœ¬')
    parser.add_argument('--stage', choices=['1', '2', '3', 'all'], default='all',
                       help='æ‰§è¡Œé˜¶æ®µ: 1(æ•°æ®æ”¶é›†), 2(ç ”æŠ¥ç”Ÿæˆ), 3(æ–‡æ¡£è½¬æ¢), all(å®Œæ•´æµç¨‹)')
    parser.add_argument('--company', default='å•†æ±¤ç§‘æŠ€', help='ç›®æ ‡å…¬å¸åç§°')
    parser.add_argument('--code', default='00020', help='è‚¡ç¥¨ä»£ç ')
    parser.add_argument('--market', default='HK', help='å¸‚åœºä»£ç ')
    parser.add_argument('--search-engine', choices=['ddg', 'sogou', 'all'], default='all',
                       help='æœç´¢å¼•æ“é€‰æ‹©')
    parser.add_argument('--input', help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºé˜¶æ®µ2æˆ–3ï¼‰')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    # æ ¹æ®é˜¶æ®µæ‰§è¡Œä¸åŒçš„æµç¨‹
    if args.stage == '1':
        # ä»…æ‰§è¡Œæ•°æ®æ”¶é›†
        logger.info("ğŸš€ ä»…æ‰§è¡Œæ•°æ®æ”¶é›†æµç¨‹")
        success = run_data_collection(args.company, args.code, args.market, args.search_engine)
        if success:
            print("\nğŸ‰ æ•°æ®æ”¶é›†æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        else:
            print("\nâŒ æ•°æ®æ”¶é›†æµç¨‹æ‰§è¡Œå¤±è´¥ï¼")
            
    elif args.stage == '2':
        # ä»…æ‰§è¡Œç ”æŠ¥ç”Ÿæˆ
        logger.info("ğŸš€ ä»…æ‰§è¡Œç ”æŠ¥ç”Ÿæˆæµç¨‹")
        md_file = run_report_generation(args.company, args.code, args.market)
        if md_file:
            print(f"\nğŸ‰ ç ”æŠ¥ç”Ÿæˆæµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
            print(f"ğŸ“‹ ç ”æŠ¥æ–‡ä»¶: {md_file}")
        else:
            print("\nâŒ ç ”æŠ¥ç”Ÿæˆæµç¨‹æ‰§è¡Œå¤±è´¥ï¼")
            
    elif args.stage == '3':
        # ä»…æ‰§è¡Œæ–‡æ¡£è½¬æ¢
        logger.info("ğŸš€ ä»…æ‰§è¡Œæ–‡æ¡£è½¬æ¢æµç¨‹")
        result = run_document_conversion(args.input)
        if result:
            print(f"\nğŸ‰ æ–‡æ¡£è½¬æ¢æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
            print(f"ğŸ“„ åŸå§‹æ–‡ä»¶: {result['original_md']}")
            print(f"ğŸ“ å¤„ç†åæ–‡ä»¶: {result['processed_md']}")
            print(f"ğŸ“‹ Wordæ–‡æ¡£: {result['docx']}")
        else:
            print("\nâŒ æ–‡æ¡£è½¬æ¢æµç¨‹æ‰§è¡Œå¤±è´¥ï¼")
            
    else:
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        logger.info("ğŸš€ æ‰§è¡Œå®Œæ•´ç ”æŠ¥ç”Ÿæˆæµç¨‹")
        success = run_full_pipeline(args.company, args.code, args.market, args.search_engine)
        if success:
            print("\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        else:
            print("\nâŒ å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥ï¼")

if __name__ == "__main__":
    main() 