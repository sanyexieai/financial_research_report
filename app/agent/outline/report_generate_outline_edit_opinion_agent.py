
from typing import List

import tiktoken
import yaml

from app.prompt.outline.generate_outline_edit_opinion import SYSTEM_PROMPT_OUTLINE_EDIT_OPINION, \
    USER_PROMPT_OUTLINE_EDIT_OPINION
from app.report_info import ReportInfo
from llm.schema import Message, Memory
from company.agent.token_counter import TokenCounter


class ReportGenerateOutlineEditOpinionAgent:
    system_prompt: str = SYSTEM_PROMPT_OUTLINE_EDIT_OPINION
        # """
        # ä½ æ˜¯ä¸€ä½é¡¶çº§é‡‘èžåˆ†æžå¸ˆå’Œç ”æŠ¥æ’°å†™ä¸»ç®¡ç ”ç©¶å‘˜ï¼Œåˆ†æ®µå¤§çº²å¿…é¡»ç”¨```yamlåŒ…è£¹ã€‚
        # """

    # llm: Optional[LLM] = Field(default_factory=LLM)

    # ç§»é™¤è¿™è¡Œæœ‰é—®é¢˜çš„ç±»å˜é‡å®šä¹‰
    # memory: Memory = Field(default_factory=Memory)

    def __init__(self, logger, llm):
        self.logger = logger
        self.llm = llm
        self.total_input_tokens = 0
        self.total_completion_tokens = 0
        self.max_input_tokens = llm.config.max_tokens
        # æ­£ç¡®åˆå§‹åŒ– Memory å®žä¾‹
        self.memory = Memory()
        # ä¿®å¤ï¼šåº”è¯¥ä½¿ç”¨ self.memory è€Œä¸æ˜¯ self.messages
        messages = [
            Message.system_message(  # ä¿®å¤ï¼šåº”è¯¥ä½¿ç”¨ system_message è€Œä¸æ˜¯ user_message
                self.system_prompt
            )
        ]
        self.memory.add_messages(messages)
        
        # ä¿®å¤ tokenizer åˆå§‹åŒ–é—®é¢˜
        try:
            self.tokenizer = tiktoken.encoding_for_model(self.llm.config.model)
        except KeyError:
            # å¦‚æžœæ¨¡åž‹ä¸è¢«æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤çš„ cl100k_base ç¼–ç ï¼ˆé€‚ç”¨äºŽå¤§å¤šæ•°çŽ°ä»£æ¨¡åž‹ï¼‰
            self.logger.warning(f"æ¨¡åž‹ {self.llm.config.model} ä¸è¢« tiktoken æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤ç¼–ç  cl100k_base")
            self.tokenizer = tiktoken.get_encoding("cl100k_base")
        
        self.token_counter = TokenCounter(self.tokenizer)

    def generate_outline_opinion(self,report_info:ReportInfo):

        part = report_info.report_outline
        if not part:
            self.logger.info(f"æœªæ‰¾åˆ°å¤§çº²ï¼Œè·³è¿‡")
            return []

        """ç”Ÿæˆç ”æŠ¥å¤§çº²"""
        self.logger.info("ðŸ“‹ æ­£åœ¨ç”Ÿæˆç ”æŠ¥å¤§çº²æ„è§...")

        # part_title = part.get("part_title")
        # part_central_idea = part.get("part_central_idea")
        # part_desc = part.get("part_desc")
        # subsections = part.get("subsections")
        # subsection_num = subsection.get("subsection_num")
        # subsection_title = subsection.get("subsection_title")
        # subsection_central_idea = subsection.get("subsection_central_idea")
        # subsection_desc = subsection.get("subsection_desc")


        user_prompt = USER_PROMPT_OUTLINE_EDIT_OPINION.format(
            target_company= report_info.target_company,
            part_title=report_info.report_title,
            outline_content=part,
        )
        messages = [
            Message.user_message(
                user_prompt
            )
        ]
        self.memory.add_messages(messages)
        self_messages = self.messages
        # ä¿®å¤ï¼šå°† Message å¯¹è±¡è½¬æ¢ä¸º dict æ ¼å¼
        messages_dict = [msg.to_dict() for msg in self_messages]
        input_tokens = self.count_message_tokens(messages_dict)
        self.logger.info(f"ðŸ“‹ è¾“å…¥tokens:{input_tokens}")
        # if not self.check_token_limit(input_tokens):
        #     error_message = self.get_limit_error_message(input_tokens)
        #     # Raise a special exception that won't be retried
        #     raise ValueError(error_message)
        self.logger.info(f"ðŸ“‹ æç¤ºè¯:{ self.memory.messages}")

        # ä¿®å¤ï¼šåº”è¯¥ä¼ é€’ self.memory.messages è€Œä¸æ˜¯ self.messages
        response = self.llm.ask(
            self.memory.messages,
            temperature=0.3
        )

        self.logger.info(f"ðŸ“‹ å·²ç”Ÿæˆç ”æŠ¥å¤§çº²æ„è§ï¼š{response}")
        try:
            if '```yaml' in response:
                yaml_block = response.split('```yaml')[1].split('```')[0]
            else:
                yaml_block = response
            result = yaml.safe_load(yaml_block)
            if isinstance(result, dict):
                result = list(result.values())
            self.logger.info(f"ðŸ“„ ç”Ÿæˆå¤§çº²æ„è§ å†…å®¹: {result}")
            report_info.report_outline_opinion = result
            return result
        except Exception as e:
            self.logger.error(f"[å¤§çº²æ„è§yamlè§£æžå¤±è´¥] {e}")
            return []

    def count_message_tokens(self, messages: List[dict]) -> int:
        return self.token_counter.count_message_tokens(messages)

    def check_token_limit(self, input_tokens: int) -> bool:
        """Check if token limits are exceeded"""
        if self.max_input_tokens is not None:
            return (self.total_input_tokens + input_tokens) <= self.max_input_tokens
        # If max_input_tokens is not set, always return True
        return True

    def get_limit_error_message(self, input_tokens: int) -> str:
        """Generate error message for token limit exceeded"""
        if (
            self.max_input_tokens is not None
            and (self.total_input_tokens + input_tokens) > self.max_input_tokens
        ):
            return f"Request may exceed input token limit (Current: {self.total_input_tokens}, Needed: {input_tokens}, Max: {self.max_input_tokens})"

        return "Token limit exceeded"

    @property
    def messages(self) -> List[Message]:
        """Retrieve a list of messages from the agent's memory."""
        return self.memory.messages

    @messages.setter
    def messages(self, value: List[Message]):
        """Set the list of messages in the agent's memory."""
        self.memory.messages = value