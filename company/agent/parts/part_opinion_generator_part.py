
from typing import List, Dict, Any

from company.agent.base_agent import BaseOutlineAgent
from company.model.report_info import ReportInfo
from company.prompt.parts.generate_part_edit_opinion_part import USER_PROMPT_PART_EDIT_OPINION_PART, \
    SYSTEM_PROMPT_PART_EDIT_OPINION_PART
from llm.schema import Message


class PartOpinionGeneratorPart(BaseOutlineAgent):
    """å¤§çº²æ„è§ç”Ÿæˆå™¨"""
    
    def __init__(self, logger, llm):
        super().__init__(logger, llm, SYSTEM_PROMPT_PART_EDIT_OPINION_PART)
    
    def generate(self, report_info: ReportInfo, **kwargs) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ–‡ç« æ­£æ–‡æ„è§"""
        if not report_info.cur_part_context.cur_content:
            self.logger.info("æ— æ­£æ–‡å†…å®¹æ„è§ï¼Œè·³è¿‡")
            return []
        
        self.logger.info("ğŸ“‹ æ­£åœ¨ç”Ÿæˆæ­£æ–‡å†…å®¹æ„è§...")
        user_input = report_info.get_user_prompt_part_input()
        user_prompt = USER_PROMPT_PART_EDIT_OPINION_PART.format(
            **user_input
        )
        self.logger.info(f"ğŸ“‹ æ­£åœ¨ç”Ÿæˆæ­£æ–‡å†…å®¹æ„è§: {user_prompt}")
        messages = [Message.user_message(user_prompt)]
        self.memory.add_messages(messages)
        
        input_tokens = self._count_tokens(self.messages)
        self.logger.info(f"ğŸ“‹ è¾“å…¥tokens: {input_tokens}")
        
        response = self.llm.ask(self.memory.messages, temperature=0.3)
        self.logger.info(f"ğŸ“‹ å·²ç”Ÿæˆæ­£æ–‡å†…å®¹æ„è§ï¼š{response}")
        
        result = self._parse_yaml_response(response)
        report_info.cur_part_context.cur_subsection_content_opinion = result

        self._reset_memory()
        return result