import os
import time
import yaml
import openai
import logging
from datetime import datetime
from duckduckgo_search import DDGS
from pocketflow import Node, Flow
from dotenv import load_dotenv
import argparse

from utils.search_engine import SearchEngine
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­åˆå§‹åŒ– OpenAI API å¯†é’¥
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_base = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®æ—¥å¿—è®°å½•"""
    os.makedirs("logs", exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_filename = f"logs/industry_workflow_{timestamp}.log"
    
    logger = logging.getLogger('IndustryWorkflow')
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    logger.info(f"ğŸ“ è¡Œä¸šç ”ç©¶å·¥ä½œæµæ—¥å¿—å·²å¯åŠ¨: {log_filename}")
    return logger

logger = setup_logging()

class IndustryResearchFlow(Node):  # ç ”æŠ¥ç”Ÿæˆçš„å†³ç­–èŠ‚ç‚¹
    def prep(self, shared):
        context = shared.get("context", [])
        generated_sections = shared.get("generated_sections", [])
        context_str = yaml.dump(context, allow_unicode=True)
        industry = shared["industry"]  # è¡Œä¸šåç§°
        
        # è®°å½•å·²ç”Ÿæˆçš„ç« èŠ‚åç§°
        generated_section_names = [section.get('name', '') for section in generated_sections]
        
        return industry, context_str, generated_section_names

    def exec(self, inputs):
        industry, context, generated_section_names = inputs
        logger.info(f"\næ­£åœ¨åˆ†æ {industry} è¡Œä¸šçš„ç ”ç©¶è¿›åº¦...")
        logger.info(f"å·²ç”Ÿæˆçš„ç« èŠ‚: {generated_section_names}")
        
        prompt = f"""
é’ˆå¯¹ {industry} è¡Œä¸šç ”ç©¶ï¼Œåˆ†æå·²æœ‰ä¿¡æ¯ï¼š{context}

å·²ç”Ÿæˆçš„ç« èŠ‚ï¼š{generated_section_names}

è¯·åˆ¤æ–­ä¸‹ä¸€æ­¥åº”è¯¥ï¼š
1) æœç´¢æ›´å¤šä¿¡æ¯ - å¦‚æœä¿¡æ¯ä¸è¶³
2) å¼€å§‹ç”ŸæˆæŸä¸ªç« èŠ‚å†…å®¹ - å¦‚æœä¿¡æ¯å……è¶³ä¸”è¿˜æœ‰é‡è¦ç« èŠ‚æœªç”Ÿæˆ
3) å®Œæˆç ”æŠ¥ç”Ÿæˆ - å¦‚æœæ‰€æœ‰é‡è¦ç« èŠ‚éƒ½å·²ç”Ÿæˆ

é‡è¦ç« èŠ‚æ¸…å•ï¼š
- è¡Œä¸šæ¦‚è¿°/è¡Œä¸šæ¦‚è§ˆ
- å¸‚åœºè§„æ¨¡åˆ†æ
- ç«äº‰æ ¼å±€åˆ†æ
- æŠ€æœ¯å‘å±•è¶‹åŠ¿
- æ”¿ç­–ç¯å¢ƒåˆ†æ
- é£é™©ä¸æŒ‘æˆ˜
- å‘å±•å‰æ™¯é¢„æµ‹

è¯·ä»¥ YAML æ ¼å¼è¾“å‡ºï¼š
```yaml
action: search/generate/complete  # searchè¡¨ç¤ºç»§ç»­æœç´¢ï¼Œgenerateè¡¨ç¤ºç”Ÿæˆç« èŠ‚ï¼Œcompleteè¡¨ç¤ºå®Œæˆ
reason: åšå‡ºæ­¤åˆ¤æ–­çš„åŸå› 
search_terms: # å¦‚æœæ˜¯searchï¼Œåˆ—å‡ºè¦æœç´¢çš„å…³é”®è¯åˆ—è¡¨
  - å…³é”®è¯1 
  - å…³é”®è¯2
section: # å¦‚æœæ˜¯generateï¼ŒæŒ‡å®šè¦ç”Ÿæˆçš„ç« èŠ‚åç§°
  name: ç« èŠ‚åç§° # å¦‚ï¼šè¡Œä¸šç”Ÿå‘½å‘¨æœŸ/ç«äº‰æ ¼å±€/å‘å±•è¶‹åŠ¿ç­‰
  focus: é‡ç‚¹å…³æ³¨å†…å®¹ # å…·ä½“è¦åˆ†æçš„è¦ç‚¹
```

æ³¨æ„ï¼š
- å¦‚æœæŸä¸ªç« èŠ‚å·²ç»ç”Ÿæˆè¿‡ï¼Œä¸è¦é‡å¤ç”Ÿæˆ
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œä¼˜å…ˆé€‰æ‹©search
- å¦‚æœæ‰€æœ‰é‡è¦ç« èŠ‚éƒ½å·²ç”Ÿæˆï¼Œé€‰æ‹©complete
"""
        resp = call_llm(prompt)
        try:
            yaml_str = resp.split("```yaml")[1].split("```", 1)[0].strip()
            result = yaml.safe_load(yaml_str)
        except Exception as e:
            logger.error(f"è§£æYAMLå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {resp}")
            # é»˜è®¤å®Œæˆ
            result = {"action": "complete", "reason": "è§£æå¤±è´¥ï¼Œé»˜è®¤å®Œæˆ"}
        
        # æ‰“å°å†³ç­–ç»“æœ
        logger.info(f"å†³ç­–ç»“æœ: {result['action']}")
        logger.info(f"å†³ç­–åŸå› : {result['reason']}")
        if result['action'] == 'search':
            logger.info("éœ€è¦æœç´¢çš„å…³é”®è¯:", result['search_terms'])
        elif result['action'] == 'generate':
            logger.info(f"å³å°†ç”Ÿæˆç« èŠ‚: {result['section']['name']}")
        elif result['action'] == 'complete':
            logger.info("å‡†å¤‡å®Œæˆç ”æŠ¥ç”Ÿæˆ")
        
        return result

    def post(self, shared, prep_res, exec_res):
        action = exec_res.get("action")
        if action == "search":
            shared["search_terms"] = exec_res.get("search_terms", [])
            logger.info("\n=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===")
        elif action == "generate":
            shared["current_section"] = exec_res.get("section", {})
            logger.info("\n=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===")
        elif action == "complete":
            logger.info("\n=== å¼€å§‹å®Œæˆç ”æŠ¥é˜¶æ®µ ===")
        return action

class SearchInfo(Node):  # ä¿¡æ¯æœç´¢èŠ‚ç‚¹
    def prep(self, shared):
        return shared.get("search_terms", [])

    def exec(self, search_terms):
        all_results = []
        total = len(search_terms)
        for i, term in enumerate(search_terms, 1):
            logger.info(f"\næœç´¢å…³é”®è¯ ({i}/{total}): {term}")
            results = search_web(term)
            logger.info(f"æ‰¾åˆ° {len(list(results))} æ¡ç›¸å…³ä¿¡æ¯")
            all_results.append({"term": term, "results": results})
            time.sleep(15)  # é¿å…è¯·æ±‚è¿‡å¿«
        return all_results

    def post(self, shared, prep_res, exec_res):
        context_list = shared.get("context", [])
        context_list.extend(exec_res)
        shared["context"] = context_list
        logger.info("\nä¿¡æ¯æœç´¢å®Œæˆï¼Œè¿”å›å†³ç­–èŠ‚ç‚¹...")
        return "search_done"

class GenerateSection(Node):  # ç« èŠ‚ç”ŸæˆèŠ‚ç‚¹
    def prep(self, shared):
        return (
            shared.get("industry"),
            shared.get("current_section", {}),
            shared.get("context", [])
        )

    def exec(self, inputs):
        industry, section, context = inputs
        logger.info(f"\nå¼€å§‹ç”Ÿæˆ {section['name']} ç« èŠ‚...")
        context_str = yaml.dump(context, allow_unicode=True)
        prompt = f"""
è¡Œä¸šï¼š{industry}
ç« èŠ‚ï¼š{section['name']}
é‡ç‚¹ï¼š{section['focus']}
å‚è€ƒèµ„æ–™ï¼š{context_str}

è¯·ç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€è¯¦å®çš„ç ”æŠ¥ç« èŠ‚ã€‚è¦æ±‚ï¼š
1. æ•°æ®æ”¯æ’‘å……åˆ†
2. é€»è¾‘ä¸¥è°¨
3. åˆ†ææ·±å…¥
4. ç»“æ„æ¸…æ™°
5. è¯­è¨€ä¸“ä¸š
"""
        content = call_llm(prompt)
        logger.info(f"ç« èŠ‚ {section['name']} ç”Ÿæˆå®Œæˆ!")
        logger.info(f"å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        # æ‰“å°å‰100ä¸ªå­—ç¬¦é¢„è§ˆ
        logger.info(f"å†…å®¹é¢„è§ˆ: {content[:100]}...")
        return {
            "name": section["name"],
            "content": content
        }
        

    def post(self, shared, prep_res, exec_res):
        sections = shared.get("generated_sections", [])
        sections.append(exec_res)
        shared["generated_sections"] = sections
        logger.info(f"\nç« èŠ‚ {exec_res['name']} å·²æ·»åŠ åˆ°ç”Ÿæˆåˆ—è¡¨")
        logger.info(f"å½“å‰å·²ç”Ÿæˆ {len(sections)} ä¸ªç« èŠ‚")
        logger.info("\nè¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...")
        return "continue"

class CompleteReport(Node):  # ç ”æŠ¥å®ŒæˆèŠ‚ç‚¹
    def prep(self, shared):
        return (
            shared.get("industry"),
            shared.get("generated_sections", [])
        )

    def exec(self, inputs):
        industry, sections = inputs
        logger.info(f"\n=== å¼€å§‹æ•´åˆæœ€ç»ˆç ”æŠ¥ ===")
        # æ•´åˆæ‰€æœ‰ç« èŠ‚å†…å®¹
        content = f"# {industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Š\n\n"
        for section in sections:
            logger.info(f"æ·»åŠ ç« èŠ‚: {section['name']}")
            content += f"\n## {section['name']}\n\n{section['content']}\n"
        return content

    def post(self, shared, prep_res, exec_res):
        logger.info(f"\n=== ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼===")
        logger.info(f"ç ”æŠ¥å·²ä¿å­˜åˆ° 'ç ”æŠ¥2.md' æ–‡ä»¶ä¸­")
        shared["report"] = exec_res
        return None

def call_llm(prompt: str) -> str:
    try:
        response = openai.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
        return ""

def search_web(term: str, force_refresh: bool = False):
    # with DDGS() as ddgs:
    #     results = ddgs.text(keywords=term, region="cn-zh", max_results=20)
    multi_engine = SearchEngine()
    results = multi_engine.search(term, max_results=10, force_refresh=force_refresh)
    return results

"""
ç¤ºä¾‹ç”¨æ³•
"""
if __name__ == "__main__":
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
    parser = argparse.ArgumentParser(description='è¡Œä¸šç ”ç©¶å·¥ä½œæµ')
    parser.add_argument('--industry', default='æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡', 
                       help='ç›®æ ‡è¡Œä¸šåç§°')
    parser.add_argument('--output-file', default=None,
                       help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å)')
    parser.add_argument('--max-iterations', type=int, default=10,
                       help='æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯')
    parser.add_argument('--force-refresh', action='store_true',
                       help='å¼ºåˆ¶åˆ·æ–°æœç´¢ç¼“å­˜')
    
    args = parser.parse_args()
    
    # æ„å»ºå·¥ä½œæµ
    research = IndustryResearchFlow()
    search = SearchInfo()
    generate = GenerateSection()
    complete = CompleteReport()
    
    # è®¾ç½®è½¬æ¢å…³ç³»
    research - "search" >> search
    research - "generate" >> generate
    research - "complete" >> complete
    search - "search_done" >> research
    generate - "continue" >> research
    
    # è¿è¡Œå·¥ä½œæµ
    flow = Flow(start=research)
    shared_state = {
        "industry": args.industry,
        "max_iterations": args.max_iterations,
        "current_iteration": 0,
        "force_refresh": args.force_refresh
    }
    
    logger.info(f"ğŸš€ å¼€å§‹è¡Œä¸šç ”ç©¶å·¥ä½œæµ")
    logger.info(f"ğŸ“Š ç›®æ ‡è¡Œä¸š: {args.industry}")
    logger.info(f"ğŸ”„ æœ€å¤§è¿­ä»£æ¬¡æ•°: {args.max_iterations}")
    if args.force_refresh:
        logger.info("ğŸ”„ å¼ºåˆ¶åˆ·æ–°æœç´¢ç¼“å­˜")
    
    result = flow.run(shared_state)
    
    # ä¿å­˜ç»“æœ
    if result:
        if args.output_file:
            output_filename = args.output_file
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{args.industry.replace('&', '_').replace(' ', '_')}_è¡Œä¸šç ”æŠ¥_{timestamp}.md"
        
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(result)
        
        logger.info(f"\nâœ… è¡Œä¸šç ”æŠ¥ç”Ÿæˆå®Œæˆï¼")
        logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_filename}")
    else:
        logger.error("âŒ ç ”æŠ¥ç”Ÿæˆå¤±è´¥")
