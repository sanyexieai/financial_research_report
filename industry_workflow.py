import os
import time
import yaml
import openai
import logging
from datetime import datetime
from duckduckgo_search import DDGS
from pocketflow import Node, Flow
from dotenv import load_dotenv
import argparse

from utils.search_engine import SearchEngine
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­åˆå§‹åŒ– OpenAI API å¯†é’¥
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_base = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®æ—¥å¿—è®°å½•"""
    os.makedirs("logs", exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_filename = f"logs/industry_workflow_{timestamp}.log"
    
    logger = logging.getLogger('IndustryWorkflow')
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    logger.info(f"ğŸ“ è¡Œä¸šç ”ç©¶å·¥ä½œæµæ—¥å¿—å·²å¯åŠ¨: {log_filename}")
    return logger

logger = setup_logging()

class IndustryResearchFlow(Node):  # ç ”æŠ¥ç”Ÿæˆçš„å†³ç­–èŠ‚ç‚¹
    def prep(self, shared):
        context = shared.get("context", [])
        generated_sections = shared.get("generated_sections", [])
        context_str = yaml.dump(context, allow_unicode=True)
        industry = shared["industry"]  # è¡Œä¸šåç§°
        # è®°å½•å·²ç”Ÿæˆçš„ç« èŠ‚åç§°
        generated_section_names = [section.get('name', '') for section in generated_sections]
        return industry, context_str, generated_section_names, shared

    def exec(self, inputs):
        industry, context, generated_section_names, shared = inputs
        logger.info(f"\næ­£åœ¨åˆ†æ {industry} è¡Œä¸šçš„ç ”ç©¶è¿›åº¦...")
        logger.info(f"å·²ç”Ÿæˆçš„ç« èŠ‚: {generated_section_names}")
        while True:
            prompt = f"""
é’ˆå¯¹ {industry} è¡Œä¸šç ”ç©¶ï¼Œåˆ†æå·²æœ‰ä¿¡æ¯ï¼š{context}

å·²ç”Ÿæˆçš„ç« èŠ‚ï¼š{generated_section_names}

è¯·åˆ¤æ–­ä¸‹ä¸€æ­¥åº”è¯¥ï¼š
1) æœç´¢æ›´å¤šä¿¡æ¯ - å¦‚æœä¿¡æ¯ä¸è¶³
2) å¼€å§‹ç”ŸæˆæŸä¸ªç« èŠ‚å†…å®¹ - å¦‚æœä¿¡æ¯å……è¶³ä¸”è¿˜æœ‰é‡è¦ç« èŠ‚æœªç”Ÿæˆ
3) å®Œæˆç ”æŠ¥ç”Ÿæˆ - å¦‚æœæ‰€æœ‰é‡è¦ç« èŠ‚éƒ½å·²ç”Ÿæˆ

é‡è¦ç« èŠ‚æ¸…å•ï¼š
- è¡Œä¸šæ¦‚è¿°/è¡Œä¸šæ¦‚è§ˆ
- å¸‚åœºè§„æ¨¡åˆ†æ
- ç«äº‰æ ¼å±€åˆ†æ
- æŠ€æœ¯å‘å±•è¶‹åŠ¿
- æ”¿ç­–ç¯å¢ƒåˆ†æ
- é£é™©ä¸æŒ‘æˆ˜
- å‘å±•å‰æ™¯é¢„æµ‹

è¯·ä»¥ YAML æ ¼å¼è¾“å‡ºï¼š
```yaml
action: search/generate/complete  # searchè¡¨ç¤ºç»§ç»­æœç´¢ï¼Œgenerateè¡¨ç¤ºç”Ÿæˆç« èŠ‚ï¼Œcompleteè¡¨ç¤ºå®Œæˆ
reason: åšå‡ºæ­¤åˆ¤æ–­çš„åŸå› 
search_terms: # å¦‚æœæ˜¯searchï¼Œåˆ—å‡ºè¦æœç´¢çš„å…³é”®è¯åˆ—è¡¨
  - å…³é”®è¯1 
  - å…³é”®è¯2
section: # å¦‚æœæ˜¯generateï¼ŒæŒ‡å®šè¦ç”Ÿæˆçš„å•ä¸ªç« èŠ‚
  name: ç« èŠ‚åç§° # å¦‚ï¼šè¡Œä¸šæ¦‚è¿°/å¸‚åœºè§„æ¨¡åˆ†æ/ç«äº‰æ ¼å±€åˆ†æç­‰
  focus: é‡ç‚¹å…³æ³¨å†…å®¹ # å…·ä½“è¦åˆ†æçš„è¦ç‚¹
```

æ³¨æ„ï¼š
- å¦‚æœæŸä¸ªç« èŠ‚å·²ç»ç”Ÿæˆè¿‡ï¼Œä¸è¦é‡å¤ç”Ÿæˆ
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œä¼˜å…ˆé€‰æ‹©search
- å¦‚æœæ‰€æœ‰é‡è¦ç« èŠ‚éƒ½å·²ç”Ÿæˆï¼Œé€‰æ‹©complete
- sectionå­—æ®µå¿…é¡»æ˜¯ä¸€ä¸ªå•ä¸ªç« èŠ‚çš„å­—å…¸ï¼ŒåŒ…å«nameå’Œfocuså­—æ®µ
- ä¸è¦è¿”å›ç« èŠ‚åˆ—è¡¨ï¼Œåªè¿”å›ä¸€ä¸ªè¦ç”Ÿæˆçš„ç« èŠ‚
"""
            resp = call_llm(prompt)
            try:
                yaml_str = resp.split("```yaml")[1].split("```", 1)[0].strip()
                result = yaml.safe_load(yaml_str)
            except Exception as e:
                logger.error(f"è§£æYAMLå¤±è´¥: {e}")
                logger.error(f"åŸå§‹å“åº”: {resp}")
                # é»˜è®¤å®Œæˆ
                result = {"action": "complete", "reason": "è§£æå¤±è´¥ï¼Œé»˜è®¤å®Œæˆ"}
            # æ‰“å°å†³ç­–ç»“æœ
            logger.info(f"å†³ç­–ç»“æœ: {result['action']}")
            logger.info(f"å†³ç­–åŸå› : {result['reason']}")
            if result['action'] == 'search':
                search_terms = result.get('search_terms', [])
                if isinstance(search_terms, list):
                    logger.info(f"éœ€è¦æœç´¢çš„å…³é”®è¯: {search_terms}")
                else:
                    logger.warning(f"æœç´¢å…³é”®è¯æ ¼å¼é”™è¯¯: {search_terms}")
                break
            elif result['action'] == 'generate':
                section = result.get('section', {})
                if isinstance(section, dict) and 'name' in section:
                    if section['name'] in generated_section_names:
                        logger.warning(f"ç« èŠ‚ {section['name']} å·²ç”Ÿæˆï¼Œè·³è¿‡ï¼Œé‡æ–°å†³ç­–...")
                        # åˆ·æ–° generated_section_namesï¼Œé˜²æ­¢æ­»å¾ªç¯
                        generated_sections = shared.get("generated_sections", [])
                        generated_section_names = [s.get('name', '') for s in generated_sections]
                        continue
                    logger.info(f"å³å°†ç”Ÿæˆç« èŠ‚: {section['name']}")
                else:
                    logger.warning(f"ç« èŠ‚ä¿¡æ¯æ ¼å¼é”™è¯¯: {section}")
                break
            elif result['action'] == 'complete':
                logger.info("å‡†å¤‡å®Œæˆç ”æŠ¥ç”Ÿæˆ")
                break
        return result

    def post(self, shared, prep_res, exec_res):
        action = exec_res.get("action")
        if action == "search":
            search_terms = exec_res.get("search_terms", [])
            if isinstance(search_terms, list):
                shared["search_terms"] = search_terms
                logger.info("\n=== å¼€å§‹ä¿¡æ¯æœç´¢é˜¶æ®µ ===")
            else:
                logger.error(f"æœç´¢å…³é”®è¯æ ¼å¼é”™è¯¯: {search_terms}")
                return "complete"  # å‡ºé”™æ—¶ç›´æ¥å®Œæˆ
        elif action == "generate":
            section = exec_res.get("section", {})
            if isinstance(section, dict) and 'name' in section:
                # å•ä¸ªç« èŠ‚çš„æƒ…å†µ
                shared["current_section"] = section
                logger.info("\n=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ ===")
            elif isinstance(section, list) and len(section) > 0:
                # ç« èŠ‚åˆ—è¡¨çš„æƒ…å†µï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªæœªç”Ÿæˆçš„ç« èŠ‚
                generated_sections = shared.get("generated_sections", [])
                generated_names = [s.get('name', '') for s in generated_sections]
                
                for s in section:
                    if isinstance(s, dict) and 'name' in s and s['name'] not in generated_names:
                        shared["current_section"] = s
                        logger.info(f"\n=== å¼€å§‹ç« èŠ‚ç”Ÿæˆé˜¶æ®µ: {s['name']} ===")
                        break
                else:
                    # æ‰€æœ‰ç« èŠ‚éƒ½å·²ç”Ÿæˆ
                    logger.info("æ‰€æœ‰ç« èŠ‚éƒ½å·²ç”Ÿæˆï¼Œè½¬ä¸ºå®ŒæˆçŠ¶æ€")
                    return "complete"
            else:
                logger.error(f"ç« èŠ‚ä¿¡æ¯æ ¼å¼é”™è¯¯: {section}")
                return "complete"  # å‡ºé”™æ—¶ç›´æ¥å®Œæˆ
        elif action == "complete":
            logger.info("\n=== å¼€å§‹å®Œæˆç ”æŠ¥é˜¶æ®µ ===")
        return action

class SearchInfo(Node):  # ä¿¡æ¯æœç´¢èŠ‚ç‚¹
    def prep(self, shared):
        return shared.get("search_terms", [])

    def exec(self, search_terms):
        all_results = []
        total = len(search_terms)
        for i, term in enumerate(search_terms, 1):
            logger.info(f"\næœç´¢å…³é”®è¯ ({i}/{total}): {term}")
            results = search_web(term)
            logger.info(f"æ‰¾åˆ° {len(list(results))} æ¡ç›¸å…³ä¿¡æ¯")
            all_results.append({"term": term, "results": results})
            time.sleep(15)  # é¿å…è¯·æ±‚è¿‡å¿«
        return all_results

    def post(self, shared, prep_res, exec_res):
        context_list = shared.get("context", [])
        context_list.extend(exec_res)
        shared["context"] = context_list
        logger.info("\nä¿¡æ¯æœç´¢å®Œæˆï¼Œè¿”å›å†³ç­–èŠ‚ç‚¹...")
        return "search_done"

class GenerateSection(Node):  # ç« èŠ‚ç”ŸæˆèŠ‚ç‚¹
    def prep(self, shared):
        return (
            shared.get("industry"),
            shared.get("current_section", {}),
            shared.get("context", [])
        )

    def exec(self, inputs):
        industry, section, context = inputs
        # å®‰å…¨æ£€æŸ¥sectionæ ¼å¼
        if not isinstance(section, dict) or 'name' not in section:
            logger.error(f"ç« èŠ‚ä¿¡æ¯æ ¼å¼é”™è¯¯: {section}")
            return {
                "name": "é”™è¯¯ç« èŠ‚",
                "content": f"ç« èŠ‚ä¿¡æ¯æ ¼å¼é”™è¯¯: {section}"
            }
        logger.info(f"\nå¼€å§‹ç”Ÿæˆ {section['name']} ç« èŠ‚...")
        context_str = yaml.dump(context, allow_unicode=True)
        focus = section.get('focus', 'ç»¼åˆåˆ†æ')
        prompt = f"""
è¡Œä¸šï¼š{industry}
ç« èŠ‚ï¼š{section['name']}
é‡ç‚¹ï¼š{focus}
å‚è€ƒèµ„æ–™ï¼š{context_str}

è¯·ç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€è¯¦å®çš„ç ”æŠ¥ç« èŠ‚ã€‚è¦æ±‚ï¼š
1. æ•°æ®æ”¯æ’‘å……åˆ†
2. é€»è¾‘ä¸¥è°¨
3. åˆ†ææ·±å…¥
4. ç»“æ„æ¸…æ™°
5. è¯­è¨€ä¸“ä¸š
"""
        content = call_llm(prompt)
        logger.info(f"ç« èŠ‚ {section['name']} ç”Ÿæˆå®Œæˆ!")
        logger.info(f"å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        logger.info(f"å†…å®¹é¢„è§ˆ: {content[:100]}...")
        return {
            "name": section["name"],
            "content": content
        }

    def post(self, shared, prep_res, exec_res):
        sections = shared.get("generated_sections", [])
        generated_names = [s.get('name', '') for s in sections]
        if exec_res['name'] in generated_names:
            logger.warning(f"ç« èŠ‚ {exec_res['name']} å·²ç”Ÿæˆï¼Œè·³è¿‡")
            return "continue"
        sections.append(exec_res)
        shared["generated_sections"] = sections
        logger.info(f"\nç« èŠ‚ {exec_res['name']} å·²æ·»åŠ åˆ°ç”Ÿæˆåˆ—è¡¨")
        logger.info(f"å½“å‰å·²ç”Ÿæˆ {len(sections)} ä¸ªç« èŠ‚")
        logger.info("\nè¿”å›å†³ç­–èŠ‚ç‚¹ï¼Œç»§ç»­åˆ†æä¸‹ä¸€æ­¥...")
        return "continue"

class CompleteReport(Node):  # ç ”æŠ¥å®ŒæˆèŠ‚ç‚¹
    def prep(self, shared):
        return (
            shared.get("industry"),
            shared.get("generated_sections", [])
        )

    def exec(self, inputs):
        industry, sections = inputs
        logger.info(f"\n=== å¼€å§‹æ•´åˆæœ€ç»ˆç ”æŠ¥ ===")
        # æ•´åˆæ‰€æœ‰ç« èŠ‚å†…å®¹
        content = f"# {industry}è¡Œä¸šç ”ç©¶æŠ¥å‘Š\n\n"
        for section in sections:
            logger.info(f"æ·»åŠ ç« èŠ‚: {section['name']}")
            content += f"\n## {section['name']}\n\n{section['content']}\n"
        return content

    def post(self, shared, prep_res, exec_res):
        logger.info(f"\n=== ç ”æŠ¥ç”Ÿæˆå®Œæˆï¼===")
        shared["report"] = exec_res
        return exec_res  # è¿”å›ç ”æŠ¥å†…å®¹è€Œä¸æ˜¯None

def call_llm(prompt: str) -> str:
    try:
        logger.info("ğŸ¤– æ­£åœ¨è°ƒç”¨LLM...")
        response = openai.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        result = response.choices[0].message.content.strip()
        logger.info(f"âœ… LLMè°ƒç”¨æˆåŠŸï¼Œè¿”å›é•¿åº¦: {len(result)}")
        return result
    except Exception as e:
        logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
        return ""

def search_web(term: str, force_refresh: bool = False):
    # with DDGS() as ddgs:
    #     results = ddgs.text(keywords=term, region="cn-zh", max_results=20)
    multi_engine = SearchEngine()
    results = multi_engine.search(term, max_results=10, force_refresh=force_refresh)
    return results

def test_workflow():
    """æµ‹è¯•å·¥ä½œæµåŸºæœ¬åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å·¥ä½œæµ...")
    
    # æµ‹è¯•LLMè°ƒç”¨
    test_prompt = "è¯·ç®€å•å›ç­”ï¼š1+1ç­‰äºå‡ ï¼Ÿ"
    result = call_llm(test_prompt)
    if result:
        logger.info(f"âœ… LLMæµ‹è¯•æˆåŠŸ: {result}")
    else:
        logger.error("âŒ LLMæµ‹è¯•å¤±è´¥")
        return False
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    try:
        results = search_web("æµ‹è¯•æœç´¢", force_refresh=True)
        logger.info(f"âœ… æœç´¢æµ‹è¯•æˆåŠŸï¼Œæ‰¾åˆ° {len(list(results))} æ¡ç»“æœ")
    except Exception as e:
        logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
    return True

"""
ç¤ºä¾‹ç”¨æ³•
"""
if __name__ == "__main__":
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ
    parser = argparse.ArgumentParser(description='è¡Œä¸šç ”ç©¶å·¥ä½œæµ')
    parser.add_argument('--industry', default='æ™ºèƒ½é£æ§&å¤§æ•°æ®å¾ä¿¡æœåŠ¡', 
                       help='ç›®æ ‡è¡Œä¸šåç§°')
    parser.add_argument('--output-file', default=None,
                       help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å)')
    parser.add_argument('--max-iterations', type=int, default=10,
                       help='æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯')
    parser.add_argument('--force-refresh', action='store_true',
                       help='å¼ºåˆ¶åˆ·æ–°æœç´¢ç¼“å­˜')
    parser.add_argument('--test', action='store_true',
                       help='ä»…è¿è¡Œæµ‹è¯•ï¼Œä¸æ‰§è¡Œå®Œæ•´å·¥ä½œæµ')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯æµ‹è¯•
    if args.test:
        test_workflow()
        exit(0)
    
    # æ„å»ºå·¥ä½œæµ
    research = IndustryResearchFlow()
    search = SearchInfo()
    generate = GenerateSection()
    complete = CompleteReport()
    
    # è®¾ç½®è½¬æ¢å…³ç³»
    research - "search" >> search
    research - "generate" >> generate
    research - "complete" >> complete
    search - "search_done" >> research
    generate - "continue" >> research
    
    # è¿è¡Œå·¥ä½œæµ
    flow = Flow(start=research)
    shared_state = {
        "industry": args.industry,
        "max_iterations": args.max_iterations,
        "current_iteration": 0,
        "force_refresh": args.force_refresh
    }
    
    logger.info(f"ğŸš€ å¼€å§‹è¡Œä¸šç ”ç©¶å·¥ä½œæµ")
    logger.info(f"ğŸ“Š ç›®æ ‡è¡Œä¸š: {args.industry}")
    logger.info(f"ğŸ”„ æœ€å¤§è¿­ä»£æ¬¡æ•°: {args.max_iterations}")
    if args.force_refresh:
        logger.info("ğŸ”„ å¼ºåˆ¶åˆ·æ–°æœç´¢ç¼“å­˜")
    
    result = flow.run(shared_state)
    
    # ä¿å­˜ç»“æœ
    if result:
        if args.output_file:
            output_filename = args.output_file
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{args.industry.replace('&', '_').replace(' ', '_')}_è¡Œä¸šç ”æŠ¥_{timestamp}.md"
        
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(result)
        
        logger.info(f"\nâœ… è¡Œä¸šç ”æŠ¥ç”Ÿæˆå®Œæˆï¼")
        logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_filename}")
    else:
        logger.error("âŒ ç ”æŠ¥ç”Ÿæˆå¤±è´¥")
        logger.error("å¯èƒ½çš„åŸå› ï¼š")
        logger.error("1. LLMè°ƒç”¨å¤±è´¥")
        logger.error("2. YAMLè§£æå¤±è´¥")
        logger.error("3. å·¥ä½œæµé€»è¾‘é”™è¯¯")
        logger.error("å»ºè®®è¿è¡Œ --test å‚æ•°è¿›è¡Œè¯Šæ–­")
